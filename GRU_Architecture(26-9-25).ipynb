{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf084a9d-0d99-46bb-872f-881d39862ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU_Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d0c363f-a6ea-4aa3-a739-329bbc4f12fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load IWDB dataset\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
    "\n",
    "max_features = 10000 # number of words to consider\n",
    "max_len = 200 # max words per review\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# Pad sequences\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len) #pad_sequences to have equal no of sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d7f8588-a5af-4866-bcb5-39a71faf58d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Build GRU model\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))  # word embeddings\n",
    "model.add(GRU(128, dropout=0.2, recurrent_dropout=0.2))  # GRU layer # remove bias\n",
    "model.add(Dense(1, activation='sigmoid'))  # 1 Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "becc1c52-28d3-4fdd-9109-c1111f772b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Compile\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88997ac3-e244-454c-ba93-945b88ecc7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m775s\u001b[0m 974ms/step - accuracy: 0.7508 - loss: 0.5017 - val_accuracy: 0.7793 - val_loss: 0.4531\n",
      "Epoch 2/3\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m637s\u001b[0m 762ms/step - accuracy: 0.8794 - loss: 0.2942 - val_accuracy: 0.8871 - val_loss: 0.2763\n",
      "Epoch 3/3\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 670ms/step - accuracy: 0.9294 - loss: 0.1826 - val_accuracy: 0.8869 - val_loss: 0.2816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x298fa64dc40>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 4: Train\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=3,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1210c534-8a38-4833-9709-ab251c403687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 110ms/step - accuracy: 0.8869 - loss: 0.2816\n",
      "Test Accuracy: 0.8869199752807617\n"
     ]
    }
   ],
   "source": [
    "#Step 5: Evaluate\n",
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(\"Test Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a804b4ac-b2fc-4891-9400-761044adbdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 555ms/step - accuracy: 0.7455 - loss: 0.5108 - val_accuracy: 0.8282 - val_loss: 0.4009\n",
      "Epoch 2/3\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 535ms/step - accuracy: 0.8566 - loss: 0.3433 - val_accuracy: 0.8510 - val_loss: 0.3454\n",
      "Epoch 3/3\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m475s\u001b[0m 576ms/step - accuracy: 0.9059 - loss: 0.2349 - val_accuracy: 0.8715 - val_loss: 0.3110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2988b4b5280>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changes\n",
    "# Modify the GRU layer units (e.g., 64, 256) and observe accuracy.\n",
    "model_gru64 = Sequential([\n",
    "    Embedding(10000, 128, input_length=200),\n",
    "    GRU(64, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_gru64.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_gru64.fit(x_train, y_train, epochs=3, batch_size=32, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fafd9df-8034-4b26-8e55-10f81b00f232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m912s\u001b[0m 1s/step - accuracy: 0.7652 - loss: 0.4816 - val_accuracy: 0.8677 - val_loss: 0.3172\n",
      "Epoch 2/3\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1052s\u001b[0m 1s/step - accuracy: 0.9033 - loss: 0.2389 - val_accuracy: 0.8865 - val_loss: 0.2703\n",
      "Epoch 3/3\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1028s\u001b[0m 1s/step - accuracy: 0.9482 - loss: 0.1397 - val_accuracy: 0.8795 - val_loss: 0.3072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x29888f59700>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the embedding dimension and observe performance.\n",
    "model_embed256 = Sequential([\n",
    "    Embedding(10000, 256, input_length=200),\n",
    "    GRU(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_embed256.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_embed256.fit(x_train, y_train, epochs=3, batch_size=32, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5fa08b5-85d1-4f5c-a2d8-04ff10f4abc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 234ms/step - accuracy: 0.7976 - loss: 0.4295 - val_accuracy: 0.8635 - val_loss: 0.3316\n",
      "Epoch 2/2\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 211ms/step - accuracy: 0.8990 - loss: 0.2550 - val_accuracy: 0.8611 - val_loss: 0.3402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2500aae1eb0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Try using LSTM instead of GRU and compare results.\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "model_lstm = Sequential([\n",
    "    Embedding(10000, 64, input_length=200),   # smaller embedding\n",
    "    LSTM(64),                                 # smaller LSTM\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_lstm.fit(x_train, y_train, epochs=2, batch_size=64, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d744258-38f9-4265-8744-f0aabb02c578",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
